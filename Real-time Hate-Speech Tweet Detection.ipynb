{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init(\"C:\\Spark\\spark-3.1.2-bin-hadoop3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover, CountVectorizer, RegexTokenizer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql.window import Window\n",
    "import preprocessor as p\n",
    "import re\n",
    "\n",
    "sc = SparkContext(appName=\"PySparkShell\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "\n",
    "def clean_tweets(df):\n",
    "    tempArr = []\n",
    "    for line in df:\n",
    "        tmpL = p.clean(line)\n",
    "        tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower())\n",
    "        tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "        tmpL = tmpL.strip()\n",
    "        tempArr.append(tmpL)\n",
    "    return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = tp.StructType([\n",
    "  tp.StructField(name= 'id',          dataType= tp.IntegerType(),  nullable= True),\n",
    "  tp.StructField(name= 'label',       dataType= tp.IntegerType(),  nullable= True),\n",
    "  tp.StructField(name= 'tweet',       dataType= tp.StringType(),   nullable= True)\n",
    "])\n",
    "    \n",
    "  \n",
    "# read the dataset  \n",
    "my_data = spark.read.csv('train.csv',\n",
    "                         schema=my_schema,\n",
    "                         header=True)\n",
    "df = my_data\n",
    "pandas_df = df.toPandas()\n",
    "clean_df = clean_tweets(pandas_df[\"tweet\"])\n",
    "clean_df = pd.DataFrame(clean_df)\n",
    "clean_df[\"id\"] = pandas_df[\"id\"]\n",
    "clean_df[\"label\"] = pandas_df[\"label\"]\n",
    "clean_spark = spark.createDataFrame(clean_df,[\"tweet\",\"id\",\"label\"])\n",
    "\n",
    "clean_spark.show(5)\n",
    "\n",
    "clean_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = RegexTokenizer(inputCol= 'tweet' , outputCol= 'tokens', pattern= '\\\\W')\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')\n",
    "stage_3 = CountVectorizer(inputCol= 'filtered_words', outputCol= 'vector')\n",
    "model = LinearSVC(featuresCol= 'vector', labelCol= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [stage_1, stage_2, stage_3, model])\n",
    "pipelineFit = pipeline.fit(clean_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the TCP Socket and then run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(tweet_text):\n",
    "    try:\n",
    "        tweet_text = tweet_text.filter(lambda x: len(x) > 0)\n",
    "        rowRdd = tweet_text.map(lambda w: Row(tweet=w))\n",
    "        wordsDataFrame = spark.createDataFrame(rowRdd)\n",
    "        wordsDataFrame = wordsDataFrame.withColumn(\"user_id\",split(F.col(\"tweet\"),\" splitterT23 \").getItem(0)).withColumn(\"user_followers\", split(F.col(\"tweet\"),\" splitterT23 \").getItem(2)).withColumn(\"actual_tweeter\", split(F.col(\"tweet\"),\" splitterT23 \").getItem(3)).withColumn(\"tweet\", split(F.col(\"tweet\"),\" splitterT23 \").getItem(1))\n",
    "        df = wordsDataFrame.select(\"tweet\")\n",
    "        pandas_df = df.toPandas()\n",
    "        clean_df = clean_tweets(pandas_df[\"tweet\"])\n",
    "        clean_df = pd.DataFrame(clean_df)\n",
    "        clean_spark = spark.createDataFrame(clean_df,[\"tweet\"])\n",
    "        clean_spark = pipelineFit.transform(clean_spark)\n",
    "        wordsDataFrame=wordsDataFrame.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "        clean_spark=clean_spark.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "        clean_spark = clean_spark.join(wordsDataFrame.select(\"row_index\",\"user_id\",\"user_followers\",\"actual_tweeter\"),on=[\"row_index\"]).drop(\"row_index\")\n",
    "        clean_spark = clean_spark.select('user_id','tweet',\"user_followers\",\"actual_tweeter\",'prediction')\n",
    "        clean_spark.show()\n",
    "        clean_spark.write.format('jdbc').options(url='jdbc:mysql://localhost:3306/demo',driver='com.mysql.cj.jdbc.Driver',dbtable='livetweets',user='root',password='root').mode('append').save()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "ssc = StreamingContext(sc, batchDuration= 3)\n",
    "lines = ssc.socketTextStream(\"localhost\", 5555)\n",
    "words = lines.flatMap(lambda line : line.split('t_end'))\n",
    "words.foreachRDD(get_prediction)\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
